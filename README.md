# IEEE-CIS Fraud Detection – CatBoost + Isolation Forest + Optuna

Проект по решению задачи **IEEE-CIS Fraud Detection** — одного из самых известных соревнований на Kaggle по обнаружению мошенничества в онлайн‑платежах.  
Датасет и постановка задачи максимально близки к реальному продакшен‑кейсу: большой объём данных, временная структура, сильный дисбаланс классов и высокий шум.

Здесь собраны эксперименты от простого baseline’a до финальной модели с тюнингом, которая отвечает базовым требованиям к боевому решению: честная валидация по времени, устойчивое качество на кросс‑валидации и интерпретируемый стек моделей.

---

## Описание задачи

Нужно предсказать, является ли транзакция мошеннической, по множеству анонимизированных признаков.  
Ключевые особенности:

- **Приближённость к боевому сценарию**: реальные паттерны транзакций, временная зависимость, анонимизация признаков.
- **Сильный дисбаланс классов**: доля fraud‑операций всего около 3–4%.
- **Высокая размерность**: сотни признаков разных типов (суммы, временные лаги, device, карты и т.д.).
- Основная метрика качества — **ROC‑AUC**, что соответствует практике оценки моделей в antifraud‑системах.

---

## Что делалось в проекте

В проекте последовательно отрабатывались разные уровни сложности, как это обычно делается при подготовке боевой модели:

1. **Baseline‑подход**  
   Простой вариант модели, чтобы:
   - проверить пайплайн загрузки и объединения данных;
   - быстро понять «порядок» метрики;
   - оценить, насколько задача вообще решаема без сложных трюков.  

   Это даёт нижнюю планку качества и служит точкой отсчёта для всех последующих улучшений.

2. **Улучшения (Improvements)**  
   После baseline фокус смещается с «справляется ли модель» на «насколько честно мы её оцениваем и насколько хорошо раскрываем данные».  
   Здесь:
   - вводится **валидация по времени (TimeSeriesSplit)**, чтобы не «подглядывать в будущее» и быть ближе к реальному продакшен‑сценарию;
   - усиливается работа с признаками (даты, агрегаты, свойства карт и т.п.);
   - пробуется **Isolation Forest** как аномалик‑модель: сначала сам по себе, затем его скор используется как дополнительный признак для основной модели.  

   На этом уровне решение уже похоже на то, что можно ставить в бою: корректная валидация, понятные фичи, отсутствие грубых утечек.

3. **Финальный тюнинг (Tuning, CatBoost + Optuna)**  
   Когда методологическая часть выстроена, акцент переносится на выжимание максимального качества:
   - используется CatBoost на GPU;
   - гиперпараметры перебираются с помощью Optuna;
   - сохраняется временная кросс‑валидация, чтобы не жертвовать честностью ради скоринга.  

   На этом шаге отрабатывается «боевая» постановка: баланс между сложностью модели, временем обучения и стабильностью метрики.  
   Итог — модель с устойчивым **ROC‑AUC ≈ 0.91+** на кросс‑валидации, что соответствует сильному уровню для этой задачи.

---

Итог:

- Получена финальная версия модели с устойчивым **ROC‑AUC ≈ 0.912** на кросс‑валидации.
- Модель удовлетворяет основным критериям «приближённого продакшена»:
  - корректная валидация;
  - интерпретируемый стек;
  - разумный баланс между скором и сложностью.

---

## Краткое сравнение уровней

- **Baseline** – простой старт, показывает порядок метрики, но не отражает реальное качество в боевых условиях.  
- **Improvements** – методологически корректная модель (TimeSeriesSplit + фичи + аномалик‑признаки), уже можно считать рабочим решением.  
- **Tuning** – та же логика, но тщательно настроенный CatBoost, который даёт лучший и наиболее стабильный ROC‑AUC и выглядит как финальная версия модели для продакшен‑сценария.

  Сравнительная таблица метрик
Этап	PR-AUC	ROC-AUC	Precision	Recall	F1-Score	Описание
Baseline	0.4785	0.8659	0.7481	0.3339	0.4617	CatBoost с дефолтными параметрами
Improvements	0.5625 (+17.6%)	0.9150 (+5.7%)	0.3902	0.6650 (+99%)	0.4918 (+6.5%)	Feature Engineering + Manual Tuning + Threshold=0.60
Optuna Tuning	0.5515 (+15.3%)	0.9232 (+6.6%)	0.4135	0.6462 (+93.5%)	0.5043 (+9.2%)	Optuna + Isolation Forest + Threshold=0.25
