"""
plots.py - –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–°–æ–¥–µ—Ä–∂–∏—Ç:
- –ì—Ä–∞—Ñ–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ê–Ω–∞–ª–∏–∑ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
- ROC-AUC –∫—Ä–∏–≤—ã–µ
- Feature importance –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.feature_selection import mutual_info_classif

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∫—Ä–∞—Å–∏–≤—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10


def plot_class_distribution(y, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤"):
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ (–≤–∞–∂–Ω–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞).
    
    Parameters:
    -----------
    y : pd.Series or array-like
        –¢–∞—Ä–≥–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    title : str
        –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–∞
    """
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))
    
    # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ —á–∏—Å–ª–∞
    counts = pd.Series(y).value_counts()
    axes[0].bar(counts.index, counts.values, color=['green', 'red'])
    axes[0].set_xlabel('–ö–ª–∞—Å—Å')
    axes[0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
    axes[0].set_title(f'{title} (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ —á–∏—Å–ª–∞)')
    axes[0].set_xticklabels(['Non-Fraud', 'Fraud'])
    
    # –ü—Ä–æ—Ü–µ–Ω—Ç—ã
    proportions = pd.Series(y).value_counts(normalize=True) * 100
    axes[1].bar(proportions.index, proportions.values, color=['green', 'red'])
    axes[1].set_xlabel('–ö–ª–∞—Å—Å')
    axes[1].set_ylabel('–ü—Ä–æ—Ü–µ–Ω—Ç (%)')
    axes[1].set_title(f'{title} (–ø—Ä–æ—Ü–µ–Ω—Ç—ã)')
    axes[1].set_xticklabels(['Non-Fraud', 'Fraud'])
    
    for ax in axes:
        for i, v in enumerate(ax.get_height()):
            ax.text(i, v + 0.5, f'{v:.1f}', ha='center')
    
    plt.tight_layout()
    plt.show()
    
    print(f"\n–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:")
    print(f"  Non-Fraud: {counts[0]} ({proportions[0]:.2f}%)")
    print(f"  Fraud:     {counts[1]} ({proportions[1]:.2f}%)")


def plot_missing_values(data, title="–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.
    """
    missing = data.isnull().sum()
    missing = missing[missing > 0].sort_values(ascending=False)
    
    if len(missing) == 0:
        print("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
        return
    
    missing_pct = (missing / len(data)) * 100
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–æ–¥–±–∏—Ä–∞–µ–º –≤—ã—Å–æ—Ç—É –≥—Ä–∞—Ñ–∏–∫–∞
    height = max(6, len(missing) * 0.3)  # –º–∏–Ω–∏–º—É–º 6, –ø–æ 0.3 –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫
    
    fig, ax = plt.subplots(figsize=(12, height), dpi=120)  # DPI –¥–ª—è —á–µ—Ç–∫–æ—Å—Ç–∏
    ax.barh(range(len(missing)), missing_pct.values)
    ax.set_yticks(range(len(missing)))
    ax.set_yticklabels(missing_pct.index, fontsize=9)  # —É–º–µ–Ω—å—à–∏–ª–∏ —à—Ä–∏—Ñ—Ç
    ax.set_xlabel('–ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (%)', fontsize=11)
    ax.set_title(title, fontsize=13)
    
    # –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π
    for i, v in enumerate(missing_pct.values):
        ax.text(v + 0.5, i, f'{v:.1f}%', va='center', fontsize=8)
    
    plt.tight_layout()  # —É–±–∏—Ä–∞–µ—Ç –æ–±—Ä–µ–∑–∞–Ω–∏–µ –º–µ—Ç–æ–∫
    plt.show()


def analyze_transaction_amt(train, target_col='isFraud', figsize=(18, 12)):
    """
    –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ TransactionAmt —Å 8 –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.
    
    Args:
        train: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        target_col: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        figsize: —Ä–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    """
    
    # –°–æ–∑–¥–∞–µ–º –±–æ–ª—å—à—É—é —Ñ–∏–≥—É—Ä—É —Å 8 –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    fig = plt.figure(figsize=figsize)
    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
    fig.suptitle('–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ TransactionAmt', fontsize=16, fontweight='bold', y=0.995)
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –ª–æ–≥–æ–º
    ax1 = fig.add_subplot(gs[0, :2])
    for fraud_val in [0, 1]:
        subset = train[train[target_col] == fraud_val]['TransactionAmt']
        label = 'Fraud' if fraud_val == 1 else 'Normal'
        color = 'red' if fraud_val == 1 else 'green'
        ax1.hist(subset, bins=100, alpha=0.6, label=label, color=color, density=True)
    ax1.set_xscale('log')
    ax1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—É–º–º: Fraud vs Normal', fontsize=12, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: Violin plot
    ax2 = fig.add_subplot(gs[0, 2])
    sns.violinplot(data=train, y='TransactionAmt', x=target_col, palette=['green', 'red'], ax=ax2)
    ax2.set_yscale('log')
    ax2.set_title('Violin plot', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    
    # –ì—Ä–∞—Ñ–∏–∫ 3: Fraud Rate –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º
    ax3 = fig.add_subplot(gs[1, 0])
    train['amt_quantile'] = pd.qcut(train['TransactionAmt'], q=20, duplicates='drop')
    fraud_by_quantile = train.groupby('amt_quantile')[target_col].agg(['mean', 'count']).reset_index()
    fraud_by_quantile['fraud_rate'] = fraud_by_quantile['mean'] * 100
    x_pos = range(len(fraud_by_quantile))
    colors_bar = ['red' if x > train[target_col].mean()*100 else 'orange' for x in fraud_by_quantile['fraud_rate']]
    ax3.bar(x_pos, fraud_by_quantile['fraud_rate'], color=colors_bar, edgecolor='black', alpha=0.8)
    ax3.axhline(y=train[target_col].mean()*100, color='blue', linestyle='--', linewidth=2, label='–°—Ä–µ–¥–Ω–∏–π fraud rate')
    ax3.set_title('Fraud Rate –ø–æ –∫–≤–∞–Ω—Ç–∏–ª—è–º', fontsize=12, fontweight='bold')
    ax3.set_xticks(range(0, len(fraud_by_quantile), 2))
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')
    
    # –ì—Ä–∞—Ñ–∏–∫ 4: CDF
    ax4 = fig.add_subplot(gs[1, 1])
    for fraud_val in [0, 1]:
        subset = train[train[target_col] == fraud_val]['TransactionAmt'].sort_values()
        label = 'Fraud' if fraud_val == 1 else 'Normal'
        color = 'red' if fraud_val == 1 else 'green'
        ax4.plot(subset.values, np.linspace(0, 1, len(subset)), label=label, color=color, linewidth=2)
    ax4.set_xscale('log')
    ax4.set_title('CDF: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π', fontsize=12, fontweight='bold')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ 5: Heatmap –°—É–º–º–∞ √ó –ß–∞—Å
    ax5 = fig.add_subplot(gs[1, 2])
    train['amt_bin'] = pd.qcut(train['TransactionAmt'], q=10, duplicates='drop', labels=False)
    train['hour_of_day'] = (train['TransactionDT'] // 3600) % 24
    pivot = train.groupby(['amt_bin', 'hour_of_day'])[target_col].mean().reset_index().pivot(
        index='amt_bin', columns='hour_of_day', values=target_col) * 100
    sns.heatmap(pivot, cmap='RdYlGn_r', annot=False, cbar_kws={'label': 'Fraud %'}, ax=ax5)
    ax5.set_title('Fraud Rate: –°—É–º–º–∞ √ó –í—Ä–µ–º—è', fontsize=12, fontweight='bold')
    
    # –ì—Ä–∞—Ñ–∏–∫ 6: Boxplot
    ax6 = fig.add_subplot(gs[2, 0])
    train_sample = train[train['TransactionAmt'] < train['TransactionAmt'].quantile(0.95)]
    sns.boxplot(data=train_sample, x=target_col, y='TransactionAmt', palette=['green', 'red'], ax=ax6, showfliers=True)
    ax6.set_title('Boxplot –±–µ–∑ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –≤—ã–±—Ä–æ—Å–æ–≤', fontsize=12, fontweight='bold')
    ax6.grid(True, alpha=0.3, axis='y')
    
    # –ì—Ä–∞—Ñ–∏–∫ 7: –¢–æ–ø-—Å—É–º–º—ã
    ax7 = fig.add_subplot(gs[2, 1])
    top_amounts = train['TransactionAmt'].value_counts().head(15)
    colors_top = ['red' if train[train['TransactionAmt']==amt][target_col].mean() > 0.1 else 'steelblue' 
                  for amt in top_amounts.index]
    ax7.barh(range(len(top_amounts)), top_amounts.values, color=colors_top, edgecolor='black', alpha=0.8)
    ax7.set_yticks(range(len(top_amounts)))
    ax7.set_yticklabels([f'${x:.0f}' for x in top_amounts.index], fontsize=9)
    ax7.set_title('–¢–æ–ø-15 –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å—É–º–º', fontsize=12, fontweight='bold')
    ax7.invert_yaxis()
    ax7.grid(True, alpha=0.3, axis='x')
    
    # –ì—Ä–∞—Ñ–∏–∫ 8: Scatter
    ax8 = fig.add_subplot(gs[2, 2])
    sample = train.sample(min(10000, len(train)), random_state=42)
    scatter = ax8.scatter(sample['TransactionDT'] / (3600*24), sample['TransactionAmt'],
                         c=sample[target_col], cmap='RdYlGn_r', alpha=0.5, s=10)
    ax8.set_yscale('log')
    ax8.set_title('Scatter: –°—É–º–º–∞ √ó –í—Ä–µ–º—è', fontsize=12, fontweight='bold')
    ax8.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax8)
    
    plt.tight_layout()
    plt.show()
    
    # –¢–µ–∫—Å—Ç–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*70)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê TransactionAmt")
    print("="*70)
    
    for fraud_val in [0, 1]:
        label = "FRAUD" if fraud_val == 1 else "NORMAL"
        subset = train[train[target_col] == fraud_val]['TransactionAmt']
        print(f"\n{label}:")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ: ${subset.mean():.2f}")
        print(f"  –ú–µ–¥–∏–∞–Ω–∞: ${subset.median():.2f}")
        print(f"  Std: ${subset.std():.2f}")
        print(f"  Min: ${subset.min():.2f}, Max: ${subset.max():.2f}")
        print(f"  Skewness: {subset.skew():.3f}")
    
    # –ö—Ä—É–≥–ª—ã–µ —Å—É–º–º—ã
    print("\n" + "-"*70)
    print("–ê–ù–ê–õ–ò–ó '–ö–†–£–ì–õ–´–•' –°–£–ú–ú")
    print("-"*70)
    round_amounts = [50, 100, 200, 500, 1000, 2000, 5000]
    for amt in round_amounts:
        if amt in train['TransactionAmt'].values:
            count = (train['TransactionAmt'] == amt).sum()
            fraud_rate = train[train['TransactionAmt'] == amt][target_col].mean() * 100
            print(f"  ${amt}: {count:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, fraud rate = {fraud_rate:.2f}%")
    
    print("\n" + "="*70)
    print("‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("="*70)
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    for col in ['amt_quantile', 'amt_bin', 'hour_of_day']:
        if col in train.columns:
            train.drop(columns=[col], inplace=True)
    
    return train


def analyze_transaction_dt(train, target_col='isFraud', figsize=(16, 10)):
    """
    –ì–ª—É–±–æ–∫–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ TransactionDT —Å 4 –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.
    
    Args:
        train: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        target_col: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        figsize: —Ä–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    """
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    train['TransactionDT_hours'] = train['TransactionDT'] / 3600
    train['TransactionDT_days'] = train['TransactionDT'] / (3600 * 24)
    train['hour_of_day'] = (train['TransactionDT'] // 3600) % 24
    train['day_of_week'] = ((train['TransactionDT'] // (3600 * 24)) % 7).astype(int)
    
    # –°–æ–∑–¥–∞–µ–º 4 –≥—Ä–∞—Ñ–∏–∫–∞
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    fig.suptitle('–í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ TransactionDT', fontsize=16, fontweight='bold', y=1.00)
    
    # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–≤ –¥–Ω—è—Ö)
    ax1 = axes[0, 0]
    ax1.hist(train['TransactionDT_days'], bins=100, color='steelblue', edgecolor='black', alpha=0.7)
    ax1.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    
    dt_min, dt_max = train['TransactionDT_days'].min(), train['TransactionDT_days'].max()
    dt_range = dt_max - dt_min
    ax1.text(0.02, 0.98, f'–ü–µ—Ä–∏–æ–¥: {dt_range:.1f} –¥–Ω–µ–π\n{dt_min:.1f} - {dt_max:.1f}', 
             transform=ax1.transAxes, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5), fontsize=9)
    
    # –ì—Ä–∞—Ñ–∏–∫ 2: –ü–æ —á–∞—Å–∞–º –¥–Ω—è
    ax2 = axes[0, 1]
    hour_counts = train['hour_of_day'].value_counts().sort_index()
    colors = plt.cm.viridis(hour_counts.values / hour_counts.values.max())
    ax2.bar(hour_counts.index, hour_counts.values, color=colors, edgecolor='black', alpha=0.8)
    ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —á–∞—Å–∞–º –¥–Ω—è', fontsize=12, fontweight='bold')
    ax2.set_xticks(range(0, 24, 2))
    ax2.grid(True, alpha=0.3, axis='y')
    
    peak_hour = hour_counts.idxmax()
    min_hour = hour_counts.idxmin()
    ax2.axvline(x=peak_hour, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'–ü–∏–∫: {peak_hour}—á')
    ax2.axvline(x=min_hour, color='green', linestyle='--', linewidth=2, alpha=0.7, label=f'–ú–∏–Ω: {min_hour}—á')
    ax2.legend()
    
    # –ì—Ä–∞—Ñ–∏–∫ 3: –ü–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
    ax3 = axes[1, 0]
    day_names = ['–ü–Ω', '–í—Ç', '–°—Ä', '–ß—Ç', '–ü—Ç', '–°–±', '–í—Å']
    day_counts = train['day_of_week'].value_counts().sort_index()
    colors_day = ['#FF6B6B' if i >= 5 else '#4ECDC4' for i in range(7)]
    ax3.bar(range(7), [day_counts.get(i, 0) for i in range(7)], color=colors_day, edgecolor='black', alpha=0.8)
    ax3.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏', fontsize=12, fontweight='bold')
    ax3.set_xticks(range(7))
    ax3.set_xticklabels(day_names)
    ax3.grid(True, alpha=0.3, axis='y')
    
    # –ì—Ä–∞—Ñ–∏–∫ 4: –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ç—Ä–µ–Ω–¥
    ax4 = axes[1, 1]
    daily_counts = train.groupby(train['TransactionDT_days'].astype(int)).size()
    ax4.plot(daily_counts.index, daily_counts.values, color='darkblue', linewidth=1.5, alpha=0.7)
    ax4.fill_between(daily_counts.index, daily_counts.values, alpha=0.3, color='steelblue')
    ax4.set_title('–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ç—Ä–µ–Ω–¥ (–ø–æ –¥–Ω—è–º)', fontsize=12, fontweight='bold')
    ax4.grid(True, alpha=0.3)
    
    if len(daily_counts) > 7:
        rolling_mean = daily_counts.rolling(window=7, center=True).mean()
        ax4.plot(rolling_mean.index, rolling_mean.values, color='red', linewidth=2, linestyle='--', label='7-–¥–Ω–µ–≤–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ')
        ax4.legend()
    
    plt.tight_layout()
    plt.show()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*60)
    print("–í–†–ï–ú–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê TransactionDT")
    print("="*60)
    print(f"\n–û–±—â–∏–π –ø–µ—Ä–∏–æ–¥: {dt_range:.1f} –¥–Ω–µ–π ({dt_range/7:.1f} –Ω–µ–¥–µ–ª—å)")
    print(f"–°—Ä–µ–¥–Ω–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ –¥–µ–Ω—å: {len(train) / dt_range:.0f}")
    print(f"–ü–∏–∫–æ–≤—ã–π —á–∞—Å: {peak_hour}:00 ({hour_counts[peak_hour]:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)")
    print(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —á–∞—Å: {min_hour}:00 ({hour_counts[min_hour]:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)")
    print(f"–°–∞–º—ã–π –∞–∫—Ç–∏–≤–Ω—ã–π –¥–µ–Ω—å: {day_names[day_counts.idxmax()]} ({day_counts.max():,})")
    print(f"–°–∞–º—ã–π —Å–ø–æ–∫–æ–π–Ω—ã–π –¥–µ–Ω—å: {day_names[day_counts.idxmin()]} ({day_counts.min():,})")
    
    # Fraud –∞–Ω–∞–ª–∏–∑
    if target_col in train.columns:
        print("\n" + "-"*60)
        print("FRAUD RATE –ü–û –í–†–ï–ú–ï–ù–ò")
        print("-"*60)
        
        hour_fraud = train.groupby('hour_of_day')[target_col].mean() * 100
        print(f"–°–∞–º—ã–π —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã–π —á–∞—Å: {hour_fraud.idxmax()}:00 ({hour_fraud.max():.2f}% fraud)")
        print(f"–°–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —á–∞—Å: {hour_fraud.idxmin()}:00 ({hour_fraud.min():.2f}% fraud)")
        
        day_fraud = train.groupby('day_of_week')[target_col].mean() * 100
        print(f"–°–∞–º—ã–π —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω—ã–π –¥–µ–Ω—å: {day_names[day_fraud.idxmax()]} ({day_fraud.max():.2f}% fraud)")
        print(f"–°–∞–º—ã–π –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–µ–Ω—å: {day_names[day_fraud.idxmin()]} ({day_fraud.min():.2f}% fraud)")
    
    # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ (–∫—Ä–æ–º–µ hour_of_day, day_of_week - –ø–æ–ª–µ–∑–Ω—ã)
    temp_cols = ['TransactionDT_hours', 'TransactionDT_days']
    train.drop(columns=[col for col in temp_cols if col in train.columns], inplace=True, errors='ignore')
    
    return train

def analyze_card_features_ultimate(train, card_features):
    """
–ì–†–ê–§–ò–ö –¥–ª—è  card_features
    """
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    risky_data = []
    for col in card_features[:6]:
        top_risky = train.groupby(col)['isFraud'].mean().sort_values(ascending=False).head(5)
        for val, rate in top_risky.items():
            if rate > 0.03:
                cnt_fraud = (train[(train[col] == val) & (train['isFraud'] == 1)]).sum()
                cnt_total = (train[col] == val).sum()
                risky_data.append([col, str(val), rate*100, cnt_fraud, cnt_total])
    
    df_risky = pd.DataFrame(risky_data, columns=['–ö–∞—Ä—Ç–∞', '–ó–Ω–∞—á–µ–Ω–∏–µ', 'Fraud%', '–§—Ä–æ–¥', '–í—Å–µ–≥–æ'])
    df_risky = df_risky.sort_values('Fraud%', ascending=True).head(20)
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))
    
    # –õ–ï–í–´–ô: –¢–û–ü-20 —Ä–∏—Å–∫–æ–≤
    y_pos = range(len(df_risky))
    bars = ax1.barh(y_pos, df_risky['Fraud%'], color='red', alpha=0.8)
    ax1.set_xlabel('FRAUD RATE %', fontsize=14, fontweight='bold')
    ax1.set_title('–¢–û–ü-20 –†–ò–°–ö–û–í–´–• –ó–ù–ê–ß–ï–ù–ò–ô –ö–ê–†–¢', fontsize=16, fontweight='bold')
    
    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ –∫–æ–ª–æ–Ω–∫–µ
    for i, (bar, fraud_pct) in enumerate(zip(bars, df_risky['Fraud%'])):
        ax1.text(bar.get_width() + 0.5, i, f'{fraud_pct:.1f}%', va='center', fontweight='bold')
    
    ax1.set_yticks(y_pos)
    ax1.set_yticklabels([f"{row['–ö–∞—Ä—Ç–∞']}={row['–ó–Ω–∞—á–µ–Ω–∏–µ']}" for _, row in df_risky.iterrows()], fontsize=11)
    ax1.grid(axis='x', alpha=0.3)
    
    # –ü–†–ê–í–´–ô: —Ä–∏—Å–∫–æ–≤ –ø–æ –∫–∞—Ä—Ç–∞–º
    card_risk_counts = []
    for col in card_features[:6]:
        risky_count = len(train.groupby(col)['isFraud'].mean()[train.groupby(col)['isFraud'].mean() > 0.05])
        card_risk_counts.append(risky_count)
    
    colors = ['red' if count > 2 else 'orange' for count in card_risk_counts]
    ax2.bar(card_features[:6], card_risk_counts, color=colors, alpha=0.8)
    ax2.set_ylabel('–ö–û–õ–ò–ß–ï–°–¢–í–û —Ä–∏—Å–∫–æ–≤', fontsize=14)
    ax2.set_title('–†–ò–°–ö–û–í–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø –ü–û –ö–ê–†–¢–ê–ú (>5%)', fontsize=16, fontweight='bold')
    ax2.tick_params(axis='x', rotation=45)
    
    # –õ–µ–≥–µ–Ω–¥–∞
    fig.legend(['–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–π', 'Fraud %'], loc='upper center', bbox_to_anchor=(0.5, 0.02))
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.15)
    plt.show()

def analyze_addr_top_charts(train, addr_features):
    """
    –¢–û–ü –ì–†–ê–§–ò–ö–ò –î–õ–Ø addr_features –∏–∑ Kaggle IEEE CIS Fraud
    """
    
    
    # ‚úÖ 2 Heatmap addr1 x addr2 (–æ—Å—Ç–∞–≤–ª—è–µ–º)
    plt.figure(figsize=(12, 10))
    top_addr1_idx = train['addr1'].value_counts().head(10).index
    top_addr2_idx = train['addr2'].value_counts().head(10).index
    
    sub_train = train[train['addr1'].isin(top_addr1_idx) & 
                     train['addr2'].isin(top_addr2_idx)]
    pivot = sub_train.groupby(['addr1', 'addr2'])['isFraud'].mean().unstack(fill_value=0) * 100
    
    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn_r', 
                cbar_kws={'label': 'Fraud %'})
    plt.title('addr1 √ó addr2: –†–ò–°–ö–û–í–´–ï –ö–û–ú–ë–ò–ù–ê–¶–ò–ò\n(–ö–†–ê–°–ù–´–ô=–æ–ø–∞—Å–Ω–æ, –ó–ï–õ–ï–ù–´–ô=–±–µ–∑–æ–ø–∞—Å–Ω–æ)', 
              fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.show()

    
    print("\nüìä –ì–†–ê–§–ò–ö (–¢–ï–ü–õ–û–í–ê–Ø –ö–ê–†–¢–ê):")
    print("  ‚Ä¢ –°—Ç—Ä–æ–∫–∏ = addr1 (—Ä–µ–≥–∏–æ–Ω—ã)")
    print("  ‚Ä¢ –°—Ç–æ–ª–±—Ü—ã = addr2 (—Å—Ç—Ä–∞–Ω—ã)") 
    print("  ‚Ä¢ –¶–∏—Ñ—Ä—ã = % –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")
    print("  ‚Ä¢ –ö–†–ê–°–ù–´–ô = –û–ü–ê–°–ù–û (>5%)")
    print("  ‚Ä¢ –ó–ï–õ–ï–ù–´–ô = –ë–ï–ó–û–ü–ê–°–ù–û (<1%)")
    
    # ‚úÖ –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´
    print("\n" + "üö® –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê" + "="*50)
    print(f"‚úÖ –ù–æ—Ä–º–∞ —Ñ—Ä–æ–¥–∞: {train['isFraud'].mean()*100:.1f}%")

    
def analyze_c_features_simple(train, c_features):
    """
    –ü–†–û–°–¢–û–ô –ê–ù–ê–õ–ò–ó C_features - –° –ü–û–õ–ù–´–ú–ò –ü–û–Ø–°–ù–ï–ù–ò–Ø–ú–ò!
    """
    
    # 1. –¢–û–ü-10 C_features –ø–æ —Ä–∞–∑–Ω–∏—Ü–µ –§–†–û–î vs –ù–û–†–ú–ê–õ–¨–ù–´–ï
    plt.figure(figsize=(12, 8))
    
    diff_stats = []
    for col in c_features[:20]:
        fraud_mean = train[train['isFraud']==1][col].mean()
        normal_mean = train[train['isFraud']==0][col].mean()
        diff = normal_mean - fraud_mean
        diff_stats.append((col, diff))
    
    diff_stats.sort(key=lambda x: x[1], reverse=True)
    top10 = diff_stats[:10]
    
    plt.barh(range(10), [x[1] for x in top10], color='green', alpha=0.7)
    plt.yticks(range(10), [x[0] for x in top10])
    plt.xlabel('–ù–û–†–ú–ê–õ–¨–ù–´–ï - –§–†–û–î (–±–æ–ª—å—à–µ = –ª—É—á—à–µ —Ñ–∏—á–∞)')
    plt.title('–¢–û–ü-10 C_features\n(–¥–ª–∏–Ω–Ω–µ–µ –±–∞—Ä = –ª—É—á—à–µ —Ñ–∏—á–∞)', fontsize=16)
    
    for i, (col, diff) in enumerate(top10):
        plt.text(diff + 0.01, i, f'{diff:.3f}', va='center', fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    # 2. HISTOGRAMM –¢–û–ü-1 —Ñ–∏—á–∏
    top_feature = top10[0][0]
    plt.figure(figsize=(12, 6))
    
    plt.hist(train[train['isFraud']==0][top_feature], bins=50, alpha=0.7, label='–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ', color='blue')
    plt.hist(train[train['isFraud']==1][top_feature], bins=50, alpha=0.7, label='–§–†–û–î', color='red')
    
    plt.xlabel(f'{top_feature}')
    plt.ylabel('–ö–û–õ–ò–ß–ï–°–¢–í–û –õ–Æ–î–ï–ô')
    plt.title(f'{top_feature}: –§–†–û–î –°–õ–ï–í–ê, –ù–û–†–ú–ê –°–ü–†–ê–í–ê!', fontsize=16)
    plt.legend()
    plt.tight_layout()
    plt.show()
    
    # ‚úÖ –° –ü–û–õ–ù–´–ú–ò –ü–û–Ø–°–ù–ï–ù–ò–Ø–ú–ò!
    print("\n" + "="*70)
    print("üìñ –ß–¢–û –ü–û–ö–ê–ó–ê–õ–ò –ì–†–ê–§–ò–ö–ò:")
    print("="*70)
    print("\nüìä –ü–ï–†–í–´–ô –ì–†–ê–§–ò–ö (–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –∑–µ–ª–µ–Ω—ã–µ –±–∞—Ä—ã):")
    print("  ‚Ä¢ –ò–ú–Ø –°–õ–ï–í–ê = –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∏—á–∏ (C1, C2, C13...)")
    print("  ‚Ä¢ –î–õ–ò–ù–ê –ë–ê–†–ê = –Ω–∞—Å–∫–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤–Ω–µ–µ —Ñ—Ä–æ–¥–∞")
    print("  ‚Ä¢ –ß–ò–°–õ–û –°–ü–†–ê–í–ê = —Ä–∞–∑–Ω–∏—Ü–∞ (0.123 = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –Ω–∞ 0.123 –∞–∫—Ç–∏–≤–Ω–µ–µ)")
    print("  ‚Ä¢ –í–ï–†–• = –õ–£–ß–®–ò–ï —Ñ–∏—á–∏ –¥–ª—è –º–æ–¥–µ–ª–∏!")
    
    print("\nüìä –í–¢–û–†–û–ô –ì–†–ê–§–ò–ö (–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞):")
    print("  ‚Ä¢ –°–ò–ù–ò–ô –•–í–û–°–¢ –°–ü–†–ê–í–ê = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã (–º–Ω–æ–≥–æ –ø–æ–∫—É–ø–æ–∫)")
    print("  ‚Ä¢ –ö–†–ê–°–ù–´–ô –•–í–û–°–¢ –°–õ–ï–í–ê = —Ñ—Ä–æ–¥ (–º–∞–ª–æ –ø–æ–∫—É–ø–æ–∫)")
    print("  ‚Ä¢ X –æ—Å—å = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫—É–ø–æ–∫ –∑–∞ N —Å–µ–∫—É–Ω–¥")
    print("  ‚Ä¢ Y –æ—Å—å = —Å–∫–æ–ª—å–∫–æ –ª—é–¥–µ–π —Å —Ç–∞–∫–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º")
    
    print("\nüî• –ó–ù–ê–ß–ï–ù–ò–Ø:")
    print(f"–¢–û–ü —Ñ–∏—á–∞: {top_feature}")
    print(f"–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ: {train[train['isFraud']==0][top_feature].mean():.1f} –ø–æ–∫—É–ø–æ–∫")
    print(f"–§–†–û–î:       {train[train['isFraud']==1][top_feature].mean():.1f} –ø–æ–∫—É–ø–æ–∫")
    
    print("\nüí° –§–ò–ß–ê –î–õ–Ø –ú–û–î–ï–õ–ò:")
    print(f"train['–Ω–∏–∑–∫–∞—è_–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å'] = (train['{top_feature}'] < 1)")
    
def analyze_d_features_simple(train, d_features):
    """
    –ü–†–û–°–¢–´–ï –ì–†–ê–§–ò–ö–ò –î–õ–Ø D_features - –ü–û–õ–ù–û–ï –ü–û–ù–Ø–¢–ò–ï!
    D1-D15 = –¥–Ω–µ–π —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    """
    
    print("üî• D_features = –°–ö–û–õ–¨–ö–û –î–ù–ï–ô –ù–ê–ó–ê–î –ë–´–õ–ê –ü–û–°–õ–ï–î–ù–Ø–Ø –ü–û–ö–£–ü–ö–ê")
    print("D1 = –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –ø–æ —ç—Ç–æ–π –∫–∞—Ä—Ç–µ")
    print("D2 = –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –ø–æ —ç—Ç–æ–º—É email")
    
    # 1. –°–ê–ú–´–ô –ü–†–û–°–¢–û–ô –ì–†–ê–§–ò–ö - D1 —Ñ—Ä–æ–¥ vs –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ
    plt.figure(figsize=(12, 8))
    
    d1_normal = train[train['isFraud']==0]['D1'].dropna()
    d1_fraud = train[train['isFraud']==1]['D1'].dropna()
    
    plt.hist(d1_normal, bins=50, alpha=0.7, label=f'–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ\n—Å—Ä–µ–¥–Ω–µ–µ={d1_normal.mean():.1f} –¥–Ω–µ–π', color='blue')
    plt.hist(d1_fraud, bins=50, alpha=0.7, label=f'–§–†–û–î\n—Å—Ä–µ–¥–Ω–µ–µ={d1_fraud.mean():.1f} –¥–Ω–µ–π', color='red')
    
    plt.xlabel('D1 (–¥–Ω–µ–π —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏)')
    plt.ylabel('–ö–û–õ–ò–ß–ï–°–¢–í–û –õ–Æ–î–ï–ô')
    plt.title('D1: –§–†–û–î –î–ê–í–ù–û –ù–ï –ü–û–ö–£–ü–ê–õ!', fontsize=16, fontweight='bold')
    plt.legend()
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    print("‚úÖ –ì–†–ê–§–ò–ö 1 - –ß–¢–û –ó–ù–ê–ß–ò–¢:")
    print("‚Ä¢ –°–ò–ù–ò–ô –≥—Ä–∞—Ñ–∏–∫ = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç—ã")
    print("‚Ä¢ –ö–†–ê–°–ù–´–ô –≥—Ä–∞—Ñ–∏–∫ = —Ñ—Ä–æ–¥")
    print("‚Ä¢ –§–†–û–î –ü–†–ê–í–ï–ï = –¥–æ–ª—å—à–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª–∏!")
    
    # 2. –¢–û–ü-5 D_features –ø–æ —Ä–∞–∑–Ω–∏—Ü–µ
    plt.figure(figsize=(12, 8))
    
    diff_stats = []
    for col in ['D1','D2','D3','D4','D5']:
        if col in train.columns:
            fraud_mean = train[train['isFraud']==1][col].mean()
            normal_mean = train[train['isFraud']==0][col].mean()
            diff = fraud_mean - normal_mean
            diff_stats.append((col, diff))
    
    diff_stats.sort(key=lambda x: x[1], reverse=True)
    top5 = diff_stats[:5]
    
    plt.barh(range(5), [x[1] for x in top5], color='orange', alpha=0.8)
    plt.yticks(range(5), [x[0] for x in top5])
    plt.xlabel('–§–†–û–î - –ù–û–†–ú–ê–õ–¨–ù–´–ï (–¥–Ω–µ–π)')
    plt.title('–¢–û–ü-5 D_features\n(–ø—Ä–∞–≤–µ–µ = —Ñ—Ä–æ–¥ –¥–æ–ª—å—à–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª)', fontsize=16)
    
    for i, (col, diff) in enumerate(top5):
        plt.text(diff + 0.1, i, f'{diff:.1f} –¥–Ω–µ–π', va='center', fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("\n‚úÖ –ì–†–ê–§–ò–ö 2 - –ß–¢–û –ó–ù–ê–ß–ò–¢:")
    print("‚Ä¢ –û–†–ê–ù–ñ–ï–í–´–ï –ë–ê–†–´ = —Ñ—Ä–æ–¥ –¥–æ–ª—å—à–µ –Ω–µ –ø–æ–∫—É–ø–∞–ª")
    print("‚Ä¢ –î–õ–ò–ù–ê –ë–ê–†–ê = —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–Ω—è—Ö")
    print("‚Ä¢ D1 —Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π = –õ–£–ß–®–ê–Ø –§–ò–ß–ê!")
    
    # –ß–ò–°–õ–ê
    print("\nüî• –ö–û–ù–ö–†–ï–¢–ù–´–ï –ß–ò–°–õ–ê:")
    for col, diff in top5:
        fraud_mean = train[train['isFraud']==1][col].mean()
        normal_mean = train[train['isFraud']==0][col].mean()
        print(f"{col}: –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ={normal_mean:.1f}–¥, —Ñ—Ä–æ–¥={fraud_mean:.1f}–¥, —Ä–∞–∑–Ω–∏—Ü–∞={diff:.1f}–¥")
    
    print("\nüí° –§–ò–ß–ò –î–õ–Ø –ú–û–î–ï–õ–ò:")
    print("train['d1_—Å—Ç–∞—Ä—ã–π'] = (train['D1'] > 30)")
    print("train['d1_d2_—Ä–∞–∑–Ω–∏—Ü–∞'] = train['D1'] - train['D2']")
    
    
def analyze_v_features_top(train, v_features):
    """
    V_features —Å –ü–û–õ–ù–´–ú–ò –ü–û–Ø–°–ù–ï–ù–ò–Ø–ú–ò –ü–û–î –ö–ê–ñ–î–´–ú –ì–†–ê–§–ò–ö–û–ú!
    """
    
    print("üî• V_features = 338 –°–ï–ö–†–ï–¢–ù–´–• —Ñ–∏—á–µ–π –æ—Ç –±–∞–Ω–∫–∞ (PCA!)")
    
    # 1. PCA 2D –ü–†–û–ï–ö–¶–ò–Ø
    print("\nüìä –ì–†–ê–§–ò–ö 1: PCA - —Ñ—Ä–æ–¥ –æ—Ç–¥–µ–ª–µ–Ω?")
    v_sample = v_features[:10]
    v_data = train[v_sample].fillna(0)
    
    scaler = StandardScaler()
    v_scaled = scaler.fit_transform(v_data)
    pca = PCA(n_components=2)
    v_pca = pca.fit_transform(v_scaled)
    
    plt.figure(figsize=(14, 10))
    scatter = plt.scatter(v_pca[:,0], v_pca[:,1], 
                         c=train['isFraud'], cmap='RdYlBu_r', alpha=0.6, s=30)
    
    plt.xlabel(f'PC1 = {pca.explained_variance_ratio_[0]:.1%} –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏')
    plt.ylabel(f'PC2 = {pca.explained_variance_ratio_[1]:.1%} –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏')
    plt.title('V_features PCA: –ö–†–ê–°–ù–´–ï=–§–†–û–î, –°–ò–ù–ò–ï=–ù–û–†–ú–ê–õ–¨–ù–´–ï', fontsize=16)
    plt.colorbar(scatter, label='0=–Ω–æ—Ä–º, 1=—Ñ—Ä–æ–¥')
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    print("‚úÖ –í–´–í–û–î –ì–†–ê–§–ò–ö–ê 1:")
    print("‚Ä¢ –ö–†–ê–°–ù–´–ï —Ç–æ—á–∫–∏ = –§–†–û–î")
    print("‚Ä¢ –°–ò–ù–ò–ï —Ç–æ—á–∫–∏ = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
    print(f"‚Ä¢ –û–±—ä—è—Å–Ω—è–µ—Ç {sum(pca.explained_variance_ratio_):.1%} –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
    print("‚Ä¢ –ï—Å–ª–∏ –∫—Ä–∞—Å–Ω—ã–µ –æ—Ç–¥–µ–ª—å–Ω–æ = V_features –æ—Ç–ª–∏—á–Ω—ã–µ!")
    
    # 2. –¢–û–ü-10 V —Ñ–∏—á–µ–π –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    print("\nüìä –ì–†–ê–§–ò–ö 2: –ö–∞–∫–∏–µ V —Ñ–∏—á–∏ –ª—É—á—à–µ –ª–æ–≤—è—Ç —Ñ—Ä–æ–¥?")
    plt.figure(figsize=(12, 8))
    
    v_corr = train[v_features[:50] + ['isFraud']].corr()['isFraud'].sort_values(ascending=False)
    top_v = v_corr[1:11]
    
    plt.barh(range(10), top_v.values, color='purple', alpha=0.7)
    plt.yticks(range(10), top_v.index)
    plt.xlabel('–°–ò–õ–ê –°–í–Ø–ó–ò –° –§–†–û–î–û–ú (–±–ª–∏–∂–µ –∫ 1 = –ª—É—á—à–µ)')
    plt.title('–¢–û–ü-10 V_features –ø–æ —Å–∏–ª–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ñ—Ä–æ–¥–∞', fontsize=16)
    
    for i, corr in enumerate(top_v.values):
        plt.text(corr + 0.0005, i, f'{corr:.4f}', va='center', fontweight='bold')
    
    plt.tight_layout()
    plt.show()
    
    print("‚úÖ –í–´–í–û–î –ì–†–ê–§–ò–ö–ê 2:")
    print("‚Ä¢ –î–õ–ò–ù–ê –§–ò–û–õ–ï–¢–û–í–û–ì–û –ë–ê–†–ê = —Å–∏–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    print("‚Ä¢ –ü—Ä–∞–≤–µ–µ = –ª—É—á—à–µ —Ñ–∏—á–∞ –¥–ª—è –º–æ–¥–µ–ª–∏")
    print(f"‚Ä¢ –õ–£–ß–®–ê–Ø: {top_v.index[0]} (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è {top_v.values[0]:.4f})")
    
    # 3. –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–û–ü V —Ñ–∏—á–∏
    print("\nüìä –ì–†–ê–§–ò–ö 3: –ö–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç —Ç–æ–ø —Ñ–∏—á–∞?")
    top_v_feature = top_v.index[0]
    plt.figure(figsize=(14, 8))
    
    plt.hist(train[train['isFraud']==0][top_v_feature].dropna(), bins=50, alpha=0.7, 
             label=f'–ù–û–†–ú–ê–õ–¨–ù–´–ï (—Å—Ä–µ–¥–Ω–µ–µ={train[train["isFraud"]==0][top_v_feature].mean():.2f})', 
             color='blue', density=True)
    plt.hist(train[train['isFraud']==1][top_v_feature].dropna(), bins=50, alpha=0.7, 
             label=f'–§–†–û–î (—Å—Ä–µ–¥–Ω–µ–µ={train[train["isFraud"]==1][top_v_feature].mean():.2f})', 
             color='red', density=True)
    
    plt.xlabel(f'{top_v_feature} (–∑–Ω–∞—á–µ–Ω–∏–µ —Ñ–∏—á–∏)')
    plt.ylabel('–ü–õ–û–¢–ù–û–°–¢–¨ (—Å–∫–æ–ª—å–∫–æ % —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)')
    plt.title(f'{top_v_feature}: –§–†–û–î –∏ –ù–û–†–ú–ê–õ–¨–ù–´–ï –≤ –†–ê–ó–ù–´–• –º–µ—Å—Ç–∞—Ö!', fontsize=16)
    plt.legend()
    plt.tight_layout()
    plt.show()
    
    print("‚úÖ –í–´–í–û–î –ì–†–ê–§–ò–ö–ê 3:")
    print(f"‚Ä¢ –°–ò–ù–ò–ô –•–í–û–°–¢ = –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è {top_v_feature}")
    print(f"‚Ä¢ –ö–†–ê–°–ù–´–ô –•–í–û–°–¢ = —Ñ—Ä–æ–¥ –∑–Ω–∞—á–µ–Ω–∏—è {top_v_feature}")
    print("‚Ä¢ –ï—Å–ª–∏ —Ö–≤–æ—Å—Ç—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è = –æ—Ç–ª–∏—á–Ω–∞—è —Ñ–∏—á–∞!")
    
    # –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´
    print("\n" + "="*70)
    print("üéØ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´ –ü–û V_features:")
    print("="*70)
    print(f"1. PCA: —Ñ—Ä–æ–¥ {sum(train['isFraud'])*100/len(train):.2f}% –æ—Ç–¥–µ–ª–µ–Ω")
    print(f"2. –¢–û–ü —Ñ–∏—á–∞: {top_v_feature}")
    print(f"3. –í—Å–µ–≥–æ —Ñ–∏—á–µ–π: {len(v_features)}")
    
    print("\nüíé –î–õ–Ø –ú–û–î–ï–õ–ò –ë–ï–†–ò:")
    print(f"v_top10 = ['{top_v_feature}', ...]  # —Ç–æ–ø-10 –∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞ 2")
    

def plot_correlation_matrix(data, columns=None, figsize=(14, 12)):
    """
    –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–ø–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å).
    
    Parameters:
    -----------
    data : pd.DataFrame
    columns : list, optional
        –ö–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å (–µ—Å–ª–∏ None, –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ)
    figsize : tuple
        –†–∞–∑–º–µ—Ä –≥—Ä–∞—Ñ–∏–∫–∞
    """
    if columns is None:
        # –ë–µ—Ä—ë–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        data_numeric = data.select_dtypes(include=[np.number])
        if data_numeric.shape[1] > 50:
            # –ï—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ, –≤—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 50
            data_numeric = data_numeric.iloc[:, :50]
    else:
        data_numeric = data[columns]
    
    corr = data_numeric.corr()
    
    fig, ax = plt.subplots(figsize=figsize)
    sns.heatmap(corr, cmap='coolwarm', center=0, 
                square=True, linewidths=0.5, ax=ax)
    ax.set_title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞')
    plt.tight_layout()
    plt.show()
    
    
    
def plot_id_features_fraud_lift(
    train,
    target='isFraud',
    prefix='id',
    exclude=('TransactionID',),
    min_group_size=50,
    top_k_per_feat=3,
    lift_thr=2.0,
    top_n_plot=15,
    figsize=(16, 6),
    print_top=5
):
    # id-—Ñ–∏—á–∏
    id_feats = [c for c in train.columns if c.startswith(prefix) and c not in exclude]
    baseline = train[target].mean()

    # 1) –°–æ–±–∏—Ä–∞–µ–º —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å –±–æ–ª—å—à–∏–º lift
    all_top = []
    for feat in id_feats:
        if train[feat].dtype != 'object':
            continue

        fraud_lift = train.groupby(feat)[target].apply(
            lambda x: (x.mean() / baseline) if len(x) > min_group_size else 0
        )
        top_cat = fraud_lift.nlargest(top_k_per_feat)

        for cat, lift in top_cat.items():
            if lift > lift_thr:
                all_top.append((feat, cat, float(lift)))

    top_df = pd.DataFrame(all_top, columns=['id_feat', 'value', 'fraud_lift'])
    if len(top_df):
        top_df = top_df.sort_values('fraud_lift', ascending=False).head(top_n_plot)

    # 2) Missing rate
    missing_rate = train[id_feats].isnull().mean() * 100

    # --- –ü–ª–æ—Ç–∏–º ---
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)

    if len(top_df):
        # —á—Ç–æ–±—ã –±—ã–ª–æ –≤–∏–¥–Ω–æ, –∫–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è: —Å–∫–ª–µ–∏–º –≤ label
        plot_df = top_df.copy()
        plot_df['label'] = plot_df['id_feat'].astype(str) + ' = ' + plot_df['value'].astype(str)
        plot_df.sort_values('fraud_lift', ascending=True).plot(
            kind='barh', x='label', y='fraud_lift', ax=ax1, color='red', legend=False
        )
        ax1.axvline(lift_thr, color='green', ls='--')
    else:
        ax1.text(0.5, 0.5, f'–ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å lift > {lift_thr}', ha='center', va='center')
        ax1.set_axis_off()

    ax1.set_title(f'–¢–û–ü Fraud ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (lift > {lift_thr}x)')
    ax1.set_xlabel('Lift vs baseline')

    missing_rate.sort_values(ascending=False).plot(kind='bar', ax=ax2, color='orange')
    ax2.set_title(f'Missing % –ø–æ {prefix}_features')
    ax2.set_ylabel('Missing %')

    plt.tight_layout()
    plt.show()

    if print_top and len(top_df):
        print("üî• –¢–û–ü KILLERS:")
        print(top_df.head(print_top))

    return top_df, missing_rate, id_feats
    
    
def weekly_fraud_analysis(train):
    """–ù–µ–¥–µ–ª—å–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è"""
    df = train.copy()
    df["dt_day"]  = ((df["TransactionDT"] - df["TransactionDT"].min()) // 86400).astype(int)
    df["dt_week"] = (df["dt_day"] // 7).astype(int)
    
    weekly = (
        df.groupby("dt_week")
          .agg(
              n=("TransactionID", "size"),
              fraud_n=("isFraud", "sum"),
              fraud_rate=("isFraud", "mean"),
              amt_median=("TransactionAmt", "median"),
              amt_mean=("TransactionAmt", "mean"),
          )
          .reset_index()
    )
    return weekly


def plot_weekly_fraud(weekly):
    """–ì—Ä–∞—Ñ–∏–∫ –Ω–µ–¥–µ–ª—å–Ω—ã–π"""
    fig, ax1 = plt.subplots(figsize=(12, 4))
    ax1.plot(weekly["dt_week"], weekly["fraud_rate"], marker="o")
    ax1.set_xlabel("–ù–µ–¥–µ–ª—è –æ—Ç –Ω–∞—á–∞–ª–∞", fontsize=12)
    ax1.set_ylabel("–î–æ–ª—è —Ñ—Ä–æ–¥–∞", fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    ax2 = ax1.twinx()
    ax2.bar(weekly["dt_week"], weekly["n"], alpha=0.2)
    ax2.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", fontsize=12)
    
    plt.title("–ù–µ–¥–µ–ª—å–Ω–∞—è –¥–æ–ª—è —Ñ—Ä–æ–¥–∞ –∏ –æ–±—ä—ë–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", fontsize=13)
    plt.tight_layout()
    plt.show()


def daily_fraud_analysis(train):
    """–î–Ω–µ–≤–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è"""
    df = train.copy()
    df["dt_day"] = ((df["TransactionDT"] - df["TransactionDT"].min()) // 86400).astype(int)
    
    daily = (
        df.groupby("dt_day")
          .agg(
              n=("TransactionID", "size"),
              fraud_n=("isFraud", "sum"),
              fraud_rate=("isFraud", "mean"),
          )
          .reset_index()
          .sort_values("dt_day")
    )
    daily["fraud_rate_ma7"] = daily["fraud_rate"].rolling(7, min_periods=1).mean()
    return daily


def plot_daily_fraud(daily):
    """–ì—Ä–∞—Ñ–∏–∫ –¥–Ω–µ–≤–Ω–æ–π"""
    fig, ax1 = plt.subplots(figsize=(16, 6))
    ax1.plot(daily["dt_day"], daily["fraud_rate"], alpha=0.35, linewidth=1, label="–î–æ–ª—è —Ñ—Ä–æ–¥–∞ (–¥–Ω–µ–≤–Ω–∞—è)")
    ax1.plot(daily["dt_day"], daily["fraud_rate_ma7"], linewidth=2, label="–î–æ–ª—è —Ñ—Ä–æ–¥–∞ (MA7)")
    ax1.set_xlabel("–î–µ–Ω—å –æ—Ç –Ω–∞—á–∞–ª–∞", fontsize=14)
    ax1.set_ylabel("–î–æ–ª—è —Ñ—Ä–æ–¥–∞", fontsize=14)
    ax1.grid(True, alpha=0.25)
    
    ax2 = ax1.twinx()
    ax2.bar(daily["dt_day"], daily["n"], alpha=0.15, width=1.0, label="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")
    ax2.set_ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", fontsize=14)
    
    ax1.set_title("–î–Ω–µ–≤–Ω–∞—è –¥–æ–ª—è —Ñ—Ä–æ–¥–∞ –∏ –æ–±—ä—ë–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (—Å–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ–º 7 –¥–Ω–µ–π)", fontsize=17)
    ax1.legend(loc="upper left", fontsize=11)
    plt.tight_layout()
    plt.show()
    
    

def analyze_missing_by_groups(train, feature_groups):
    """
    –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –ø–æ –≥—Ä—É–ø–ø–∞–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π
    
    Parameters:
    -----------
    train : DataFrame
        –ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
    feature_groups : dict
        –°–ª–æ–≤–∞—Ä—å —Å –≥—Ä—É–ø–ø–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ {group_name: [col1, col2, ...]}
        
    Returns:
    --------
    DataFrame : summary_df —Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –ø–æ –≥—Ä—É–ø–ø–∞–º
    """
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å–≤–æ–¥–∫—É
    summary_data = []

    for group_name, cols in sorted(feature_groups.items()):
        cols_in_df = [c for c in cols if c in train.columns]
        if not cols_in_df:
            continue
        
        sub = train[cols_in_df]
        missing_count = sub.isna().sum().sum()
        total_cells = len(train) * len(cols_in_df)
        affected = (sub.isna().sum() > 0).sum()
        
        summary_data.append({
            'Group': group_name,
            'Count': len(cols_in_df),
            'Missing_%': round(missing_count / total_cells * 100, 2),
            'Affected': affected,
        })

    summary_df = pd.DataFrame(summary_data).sort_values('Missing_%', ascending=False)

    print("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê –ü–û –ì–†–£–ü–ü–ê–ú:")
    print(summary_df)
    print("\n")

    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
    fig, ax = plt.subplots(figsize=(12, 8))

    # –¶–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
    def get_color(missing_pct):
        if missing_pct > 60:
            return '#d62728'  # –∫—Ä–∞—Å–Ω—ã–π - –∫—Ä–∏—Ç–∏—á–Ω–æ
        elif missing_pct > 40:
            return '#ff7f0e'  # –æ—Ä–∞–Ω–∂–µ–≤—ã–π - –≤—ã—Å–æ–∫–æ
        elif missing_pct > 10:
            return '#ffbb78'  # —Å–≤–µ—Ç–ª–æ-–æ—Ä–∞–Ω–∂–µ–≤—ã–π - —Å—Ä–µ–¥–Ω–µ
        else:
            return '#2ca02c'  # –∑–µ–ª–µ–Ω—ã–π - —Ö–æ—Ä–æ—à–æ

    colors = [get_color(x) for x in summary_df['Missing_%']]

    # Scatter —Å —Ä–∞–∑–º–µ—Ä–æ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    scatter = ax.scatter(
        summary_df['Missing_%'], 
        summary_df['Count'],
        s=summary_df['Count'] * 10,  # —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª–µ–Ω –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        c=colors,
        alpha=0.7,
        edgecolor='black',
        linewidth=2
    )

    # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    for idx, row in summary_df.iterrows():
        ax.annotate(
            f"{row['Group']}\n({row['Affected']}/{row['Count']})",
            (row['Missing_%'], row['Count']),
            xytext=(8, 8),
            textcoords='offset points',
            fontsize=10,
            fontweight='bold',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='gray', alpha=0.8)
        )

    # –ó–æ–Ω—ã –ø–æ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏
    ax.axvspan(0, 10, alpha=0.1, color='green', label='–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ–ø—É—Å–∫–æ–≤')
    ax.axvspan(10, 40, alpha=0.1, color='yellow', label='–°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å')
    ax.axvspan(40, 60, alpha=0.1, color='orange', label='–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å')
    ax.axvspan(60, 100, alpha=0.1, color='red', label='–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å')

    ax.set_xlabel('–î–æ–ª—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ (%)', fontsize=12, fontweight='bold')
    ax.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –≥—Ä—É–ø–ø–µ', fontsize=12, fontweight='bold')
    ax.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥—Ä—É–ø–ø–∞–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.legend(loc='upper right', fontsize=9)

    # –£—Å—Ç–∞–Ω–æ–≤–∏–º —Ä–∞–∑—É–º–Ω—ã–µ –ª–∏–º–∏—Ç—ã
    ax.set_xlim(-5, 105)
    ax.set_ylim(0, max(summary_df['Count']) * 1.15)

    plt.tight_layout()
    plt.show()

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*70)
    print("–ü–†–ò–û–†–ò–¢–ò–ó–ê–¶–ò–Ø –ì–†–£–ü–ü –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò")
    print("="*70)

    for idx, row in summary_df.iterrows():
        group = row['Group']
        missing = row['Missing_%']
        count = row['Count']
        affected = row['Affected']
        
        if missing > 60:
            priority = "üî¥ –ö–†–ò–¢–ò–ß–ù–û"
            action = "–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –¥—Ä–æ–ø –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É"
        elif missing > 40:
            priority = "üü† –í–´–°–û–ö–ò–ô"
            action = "–°–æ–∑–¥–∞—Ç—å is_missing —Ñ–ª–∞–≥–∏ + –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ"
        elif missing > 10:
            priority = "üü° –°–†–ï–î–ù–ò–ô"
            action = "–ü—Ä–æ—Å—Ç–æ–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ (median/mode)"
        else:
            priority = "üü¢ –ù–ò–ó–ö–ò–ô"
            action = "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"
        
        print(f"\n{group}:")
        print(f"  –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {priority}")
        print(f"  –ü—Ä–æ–ø—É—Å–∫–∏: {missing}% ({affected}/{count} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã)")
        print(f"  –î–µ–π—Å—Ç–≤–∏–µ: {action}")
    
    return summary_df 



def print_confusion_matrix_analysis(cm, y_true, y_pred, fold_name="–ü–û–°–õ–ï–î–ù–ò–ô –§–û–õ–î"):
    """
    –í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ confusion matrix —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    
    Parameters:
    -----------
    cm : array
        Confusion matrix –æ—Ç sklearn.metrics.confusion_matrix
    y_true : array
        –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y_pred : array
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    fold_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–æ–ª–¥–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    print("\n" + "="*80)
    print(f"–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó CONFUSION MATRIX ({fold_name})")
    print("="*80)
    
    tn, fp, fn, tp = cm.ravel()
    total = tn + fp + fn + tp
    
    print(f"\n                  Predicted")
    print(f"              No Fraud  |  Fraud")
    print(f"         ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
    print(f"Actual   |              |        ")
    print(f"No Fraud |    {tn:6d}  |  {fp:6d}")
    print(f"  Fraud  |    {fn:6d}  |  {tp:6d}")
    
    print(f"\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó")
    print(f"‚ïë  True Negatives  (TN): {tn:6d} ({tn/total*100:5.2f}%)  ‚ïë")
    print(f"‚ïë  False Positives (FP): {fp:6d} ({fp/total*100:5.2f}%)  ‚ïë")
    print(f"‚ïë  False Negatives (FN): {fn:6d} ({fn/total*100:5.2f}%)  ‚ïë")
    print(f"‚ïë  True Positives  (TP): {tp:6d} ({tp/total*100:5.2f}%)  ‚ïë")
    print(f"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù")
    
    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    fpr_rate = fp / (fp + tn) if (fp + tn) > 0 else 0
    fnr_rate = fn / (fn + tp) if (fn + tp) > 0 else 0
    
    print(f"\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ CM:")
    print(f"  Sensitivity (TPR, Recall): {sensitivity:.4f}  # –¥–æ–ª—è –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–æ–¥–∞")
    print(f"  Specificity (TNR):         {specificity:.4f}  # –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –Ω–µ-—Ñ—Ä–æ–¥–æ–≤")
    print(f"  False Positive Rate (FPR): {fpr_rate:.4f}     # –¥–æ–ª—è –ª–æ–∂–Ω—ã—Ö —Ç—Ä–µ–≤–æ–≥")
    print(f"  False Negative Rate (FNR): {fnr_rate:.4f}     # –¥–æ–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–æ–¥–∞")
    
    # Classification Report
    print("\n" + "="*80)
    print(f"CLASSIFICATION REPORT ({fold_name})")
    print("="*80)
    print(classification_report(y_true, y_pred, target_names=['No Fraud', 'Fraud']))
    
    return {
        'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,
        'sensitivity': sensitivity, 'specificity': specificity,
        'fpr': fpr_rate, 'fnr': fnr_rate
    }


def print_model_metrics(y_true, y_pred_proba, y_pred, fold_name="–ü–û–°–õ–ï–î–ù–ò–ô –§–û–õ–î"):
    """
    –í—ã–≤–æ–¥–∏—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏
    
    Parameters:
    -----------
    y_true : array
        –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y_pred_proba : array
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    y_pred : array
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–±–∏–Ω–∞—Ä–Ω—ã–µ)
    fold_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–æ–ª–¥–∞
    """
    print("\n" + "="*100)
    print(f"–ú–ï–¢–†–ò–ö–ò –ù–ê –¢–ï–°–¢–û–í–û–ô –ß–ê–°–¢–ò {fold_name}")
    print("="*100)
    
    test_auc = roc_auc_score(y_true, y_pred_proba)
    test_acc = accuracy_score(y_true, y_pred)
    test_precision = precision_score(y_true, y_pred)
    test_recall = recall_score(y_true, y_pred)
    test_f1 = f1_score(y_true, y_pred)
    
    print(f"\nROC-AUC:   {test_auc:.4f}")
    print(f"Accuracy:  {test_acc:.4f}")
    print(f"Precision: {test_precision:.4f}")
    print(f"Recall:    {test_recall:.4f}")
    print(f"F1-Score:  {test_f1:.4f}")
    
    return {
        'auc': test_auc,
        'accuracy': test_acc,
        'precision': test_precision,
        'recall': test_recall,
        'f1': test_f1
    }


def plot_model_evaluation(y_true, y_pred_proba, y_pred, fold_name="Last Fold", 
                          threshold=0.5, figsize=(14, 10)):
    """
    –°—Ç—Ä–æ–∏—Ç 4 –≥—Ä–∞—Ñ–∏–∫–∞: ROC, PR Curve, Confusion Matrix, Distribution
    
    Parameters:
    -----------
    y_true : array
        –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y_pred_proba : array
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    y_pred : array
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–±–∏–Ω–∞—Ä–Ω—ã–µ)
    fold_name : str
        –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–æ–ª–¥–∞ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    threshold : float
        –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    figsize : tuple
        –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    """
    print("\n" + "="*100)
    print(f"–ü–û–°–¢–†–û–ï–ù–ò–ï –ì–†–ê–§–ò–ö–û–í ({fold_name})")
    print("="*100)
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    fpr, tpr, roc_thresholds = roc_curve(y_true, y_pred_proba)
    precision_curve, recall_curve, pr_thresholds = precision_recall_curve(y_true, y_pred_proba)
    pr_auc = average_precision_score(y_true, y_pred_proba)
    test_auc = roc_auc_score(y_true, y_pred_proba)
    cm = confusion_matrix(y_true, y_pred)
    
    print(f"ROC-AUC: {test_auc:.4f}")
    print(f"PR-AUC (Average Precision): {pr_auc:.4f}")
    
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 1: ROC Curve =====
    axes[0, 0].plot(fpr, tpr, color='steelblue', linewidth=2, 
                    label=f'ROC curve (AUC = {test_auc:.4f})')
    axes[0, 0].plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=1, 
                    label='Random classifier')
    axes[0, 0].set_xlabel('False Positive Rate', fontsize=11)
    axes[0, 0].set_ylabel('True Positive Rate', fontsize=11)
    axes[0, 0].set_title(f'ROC Curve ({fold_name})', fontsize=13, fontweight='bold')
    axes[0, 0].legend(loc='lower right')
    axes[0, 0].grid(alpha=0.3)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 2: Precision-Recall Curve =====
    axes[0, 1].plot(recall_curve, precision_curve, color='coral', linewidth=2, 
                    label=f'PR curve (AUC = {pr_auc:.4f})')
    no_skill = y_true.sum() / len(y_true)
    axes[0, 1].plot([0, 1], [no_skill, no_skill], color='red', linestyle='--', 
                    linewidth=1, label=f'Baseline ({no_skill:.3f})')
    axes[0, 1].set_xlabel('Recall', fontsize=11)
    axes[0, 1].set_ylabel('Precision', fontsize=11)
    axes[0, 1].set_title(f'Precision-Recall Curve ({fold_name})', fontsize=13, fontweight='bold')
    axes[0, 1].legend(loc='upper right')
    axes[0, 1].grid(alpha=0.3)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 3: Confusion Matrix =====
    sns.heatmap(
        cm, annot=True, fmt='d', cmap='Blues',
        xticklabels=['No Fraud', 'Fraud'],
        yticklabels=['No Fraud', 'Fraud'],
        cbar=True, square=True,
        linewidths=2, linecolor='black',
        annot_kws={"size": 16, "weight": "bold"},
        ax=axes[1, 0]
    )
    axes[1, 0].set_xlabel('Predicted Label', fontsize=11, fontweight='bold')
    axes[1, 0].set_ylabel('True Label', fontsize=11, fontweight='bold')
    axes[1, 0].set_title(f'Confusion Matrix ({fold_name})', fontsize=13, fontweight='bold')
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 4: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π =====
    axes[1, 1].hist(
        y_pred_proba[y_true == 0], bins=50, alpha=0.6, color='steelblue',
        label='No Fraud', edgecolor='black', linewidth=0.5
    )
    axes[1, 1].hist(
        y_pred_proba[y_true == 1], bins=50, alpha=0.6, color='coral',
        label='Fraud', edgecolor='black', linewidth=0.5
    )
    axes[1, 1].axvline(x=threshold, color='green' if threshold != 0.5 else 'red', 
                       linestyle='--', linewidth=2, label=f'Threshold = {threshold:.2f}')
    if threshold != 0.5:
        axes[1, 1].axvline(x=0.5, color='red', linestyle=':', linewidth=1.5, 
                           alpha=0.5, label='Default = 0.5')
    axes[1, 1].set_xlabel('Predicted Probability', fontsize=11)
    axes[1, 1].set_ylabel('Frequency', fontsize=11)
    axes[1, 1].set_title(f'Distribution of Predicted Probabilities ({fold_name})', 
                         fontsize=13, fontweight='bold')
    axes[1, 1].legend(loc='upper right')
    axes[1, 1].grid(alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return {'auc': test_auc, 'pr_auc': pr_auc, 'cm': cm}


def plot_feature_importance(importance_df, categorical_features, X_columns, 
                            title_prefix="", figsize=(16, 6)):
    """
    –°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ–≥–æ –≤–∫–ª–∞–¥–∞
    
    Parameters:
    -----------
    importance_df : DataFrame
        DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'feature' –∏ 'importance'
    categorical_features : list
        –°–ø–∏—Å–æ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X_columns : Index
        –ù–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫ X
    title_prefix : str
        –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    figsize : tuple
        –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    """
    fig, axes = plt.subplots(1, 2, figsize=figsize)
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–ª–∞–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if 'is_categorical' not in importance_df.columns:
        importance_df['is_categorical'] = importance_df['feature'].isin(categorical_features)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 1: –¢–û–ü-10 –°–∞–º—ã—Ö –í–∞–∂–Ω—ã—Ö –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ =====
    top_features = importance_df.head(10)
    colors = ['coral' if is_cat else 'steelblue' for is_cat in top_features['is_categorical']]
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å std –≤ –¥–∞–Ω–Ω—ã—Ö, –¥–æ–±–∞–≤–ª—è–µ–º error bars
    if 'importance_std' in importance_df.columns:
        axes[0].barh(top_features['feature'], top_features['importance'], 
                     color=colors, edgecolor='black', 
                     xerr=top_features['importance_std'], capsize=5, alpha=0.8)
        xlabel = 'Feature Importance (Mean ¬± Std)'
    else:
        axes[0].barh(top_features['feature'], top_features['importance'], 
                     color=colors, edgecolor='black')
        xlabel = 'Feature Importance'
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –≥—Ä–∞—Ñ–∏–∫
        for i, (feature, importance) in enumerate(zip(top_features['feature'], 
                                                       top_features['importance'])):
            axes[0].text(importance, i, f'{importance:.4f}', 
                        va='center', ha='left', fontsize=9, fontweight='bold')
    
    axes[0].set_xlabel(xlabel, fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Features', fontsize=12, fontweight='bold')
    axes[0].set_title(f'{title_prefix}–¢–û–ü-10 –°–∞–º—ã—Ö –í–∞–∂–Ω—ã—Ö –ü—Ä–∏–∑–Ω–∞–∫–æ–≤\nCatBoost –º–æ–¥–µ–ª—å', 
                      fontsize=14, fontweight='bold')
    axes[0].invert_yaxis()
    axes[0].grid(axis='x', alpha=0.3)
    
    # –õ–µ–≥–µ–Ω–¥–∞
    legend_elements = [
        Patch(facecolor='steelblue', label='–ß–∏—Å–ª–æ–≤—ã–µ'),
        Patch(facecolor='coral', label='–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ')
    ]
    axes[0].legend(handles=legend_elements, loc='lower right')
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 2: –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –í–∫–ª–∞–¥ =====
    importance_col = 'importance_mean' if 'importance_mean' in importance_df.columns else 'importance'
    importance_sorted = importance_df[importance_col].values
    cumulative_importance = np.cumsum(importance_sorted) / importance_sorted.sum() * 100
    
    axes[1].plot(range(len(cumulative_importance)), cumulative_importance, 
                 color='darkgreen', linewidth=3, label='–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –≤–∫–ª–∞–¥ (%)')
    axes[1].fill_between(range(len(cumulative_importance)), cumulative_importance, 
                          alpha=0.3, color='lightgreen')
    
    # –ü–æ—Ä–æ–≥–∏ 80% –∏ 90%
    axes[1].axhline(y=80, color='red', linestyle='--', linewidth=2, label='80% –ø–æ—Ä–æ–≥')
    axes[1].axhline(y=90, color='orange', linestyle='--', linewidth=2, label='90% –ø–æ—Ä–æ–≥')
    
    n_features_80 = np.argmax(cumulative_importance >= 80) + 1
    n_features_90 = np.argmax(cumulative_importance >= 90) + 1
    
    axes[1].axvline(x=n_features_80, color='red', linestyle=':', linewidth=1.5, alpha=0.7)
    axes[1].axvline(x=n_features_90, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)
    
    axes[1].text(n_features_80, 82, f'{n_features_80} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', 
                 fontsize=10, fontweight='bold', color='red', ha='left')
    axes[1].text(n_features_90, 92, f'{n_features_90} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', 
                 fontsize=10, fontweight='bold', color='orange', ha='left')
    
    axes[1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –≤–∫–ª–∞–¥ (%)', fontsize=12, fontweight='bold')
    axes[1].set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –í–∫–ª–∞–¥ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –ú–æ–¥–µ–ª—å', 
                      fontsize=14, fontweight='bold')
    axes[1].legend(loc='lower right', fontsize=10)
    axes[1].grid(alpha=0.3)
    axes[1].set_ylim([0, 105])
    
    plt.tight_layout()
    plt.show()
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –ê–ù–ê–õ–ò–ó –ö–£–ú–£–õ–Ø–¢–ò–í–ù–û–ì–û –í–ö–õ–ê–î–ê –ü–†–ò–ó–ù–ê–ö–û–í:")
    print(f"  ‚Ä¢ –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 80% –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è: {n_features_80} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ "
          f"({n_features_80/len(X_columns)*100:.1f}%)")
    print(f"  ‚Ä¢ –î–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 90% –≤–∞–∂–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è: {n_features_90} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ "
          f"({n_features_90/len(X_columns)*100:.1f}%)")
    print(f"  ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(X_columns)}")
    
    return {'n_features_80': n_features_80, 'n_features_90': n_features_90}


def optimize_threshold(y_true, y_pred_proba, cost_fp=10, cost_fn=100, 
                       thresholds=np.arange(0.1, 0.9, 0.05)):
    """
    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∞–º
    
    Parameters:
    -----------
    y_true : array
        –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
    y_pred_proba : array
        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    cost_fp : float
        –°—Ç–æ–∏–º–æ—Å—Ç—å False Positive (–±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ª–µ–≥–∞–ª—å–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)
    cost_fn : float
        –°—Ç–æ–∏–º–æ—Å—Ç—å False Negative (–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–π —Ñ—Ä–æ–¥)
    thresholds : array
        –ú–∞—Å—Å–∏–≤ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
    --------
    dict : –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    """
    print("\n" + "="*100)
    print("üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–û–†–û–ì–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
    print("="*100)
    
    threshold_metrics = {
        'threshold': [],
        'precision': [],
        'recall': [],
        'f1': [],
        'accuracy': [],
        'business_cost': []
    }
    
    for threshold in thresholds:
        y_pred_temp = (y_pred_proba >= threshold).astype(int)
        cm_temp = confusion_matrix(y_true, y_pred_temp)
        
        if len(cm_temp.ravel()) == 4:
            tn, fp, fn, tp = cm_temp.ravel()
        else:
            continue
        
        business_cost = fp * cost_fp + fn * cost_fn
        
        threshold_metrics['threshold'].append(threshold)
        threshold_metrics['precision'].append(precision_score(y_true, y_pred_temp, zero_division=0))
        threshold_metrics['recall'].append(recall_score(y_true, y_pred_temp, zero_division=0))
        threshold_metrics['f1'].append(f1_score(y_true, y_pred_temp, zero_division=0))
        threshold_metrics['accuracy'].append(accuracy_score(y_true, y_pred_temp))
        threshold_metrics['business_cost'].append(business_cost)
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–æ—Ä–æ–≥–∏
    optimal_f1_idx = np.argmax(threshold_metrics['f1'])
    optimal_business_idx = np.argmin(threshold_metrics['business_cost'])
    
    optimal_threshold_f1 = thresholds[optimal_f1_idx]
    optimal_threshold_business = thresholds[optimal_business_idx]
    
    print(f"\nüìä –û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –ü–û–†–û–ì–ò:")
    print(f"   –ü–æ F1-Score:        {optimal_threshold_f1:.2f} "
          f"(F1={threshold_metrics['f1'][optimal_f1_idx]:.4f})")
    print(f"   –ü–æ –±–∏–∑–Ω–µ—Å-—Å—Ç–æ–∏–º–æ—Å—Ç–∏: {optimal_threshold_business:.2f} "
          f"(Cost=${threshold_metrics['business_cost'][optimal_business_idx]:,.0f})")
    print(f"   –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –ø–æ—Ä–æ–≥:     0.50")
    
    return {
        'threshold_metrics': threshold_metrics,
        'optimal_f1': optimal_threshold_f1,
        'optimal_business': optimal_threshold_business,
        'cost_fp': cost_fp,
        'cost_fn': cost_fn
    }


def plot_threshold_analysis(threshold_results, figsize=(16, 6)):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Ä–æ–≥–æ–≤
    
    Parameters:
    -----------
    threshold_results : dict
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç optimize_threshold()
    figsize : tuple
        –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    """
    tm = threshold_results['threshold_metrics']
    thresholds = np.array(tm['threshold'])
    
    fig, axes = plt.subplots(1, 2, figsize=figsize)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 1: –ú–µ—Ç—Ä–∏–∫–∏ vs –ü–æ—Ä–æ–≥ =====
    axes[0].plot(thresholds, tm['precision'], label='Precision', linewidth=2, marker='o', markersize=4)
    axes[0].plot(thresholds, tm['recall'], label='Recall', linewidth=2, marker='s', markersize=4)
    axes[0].plot(thresholds, tm['f1'], label='F1-Score', linewidth=2, marker='^', markersize=4)
    axes[0].axvline(x=0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Default (0.5)')
    axes[0].axvline(x=threshold_results['optimal_f1'], color='green', linestyle='--', linewidth=2, 
                    label=f"Optimal F1 ({threshold_results['optimal_f1']:.2f})")
    axes[0].axvline(x=threshold_results['optimal_business'], color='purple', linestyle='--', linewidth=2, 
                    label=f"Optimal Cost ({threshold_results['optimal_business']:.2f})")
    axes[0].set_xlabel('Threshold', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Score', fontsize=12, fontweight='bold')
    axes[0].set_title('–ú–µ—Ç—Ä–∏–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ä–æ–≥–∞', fontsize=14, fontweight='bold')
    axes[0].legend(loc='best', fontsize=9)
    axes[0].grid(alpha=0.3)
    
    # ===== –ì—Ä–∞—Ñ–∏–∫ 2: –ë–∏–∑–Ω–µ—Å-—Å—Ç–æ–∏–º–æ—Å—Ç—å vs –ü–æ—Ä–æ–≥ =====
    optimal_cost = min(tm['business_cost'])
    axes[1].plot(thresholds, tm['business_cost'], color='red', linewidth=3, marker='o', markersize=6)
    axes[1].axvline(x=threshold_results['optimal_business'], color='green', linestyle='--', linewidth=2, 
                    label=f'–ú–∏–Ω–∏–º—É–º (${optimal_cost:,.0f})')
    axes[1].set_xlabel('Threshold', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Business Cost ($)', fontsize=12, fontweight='bold')
    axes[1].set_title(f"–ë–∏–∑–Ω–µ—Å-—Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—à–∏–±–æ–∫ vs –ü–æ—Ä–æ–≥\n"
                      f"(FP=${threshold_results['cost_fp']}, FN=${threshold_results['cost_fn']})", 
                      fontsize=14, fontweight='bold')
    axes[1].legend(loc='best')
    axes[1].grid(alpha=0.3)
    axes[1].ticklabel_format(style='plain', axis='y')
    
    plt.tight_layout()
    plt.show()






# def plot_feature_importance(model, feature_names, top_n=20, title="Feature Importance"):
#     """
#     –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏ (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è, –∫–∞–∫–∏–µ —Ñ–∏—á–∏ —Ä–∞–±–æ—Ç–∞—é—Ç).
    
#     Parameters:
#     -----------
#     model : sklearn model or xgb/lgb model
#         –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
#     feature_names : list
#         –ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
#     top_n : int
#         –°–∫–æ–ª—å–∫–æ —Ç–æ–ø —Ñ–∏—á –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
#     title : str
#         –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≥—Ä–∞—Ñ–∏–∫–∞
#     """
#     # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
#     if hasattr(model, 'feature_importances_'):
#         importances = model.feature_importances_
#     elif hasattr(model, 'coef_'):
#         importances = np.abs(model.coef_[0])
#     else:
#         print("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç feature importance")
#         return
    
#     # –°–æ–∑–¥–∞—ë–º dataframe –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
#     importance_df = pd.DataFrame({
#         'feature': feature_names,
#         'importance': importances
#     }).sort_values('importance', ascending=False).head(top_n)
    
#     fig, ax = plt.subplots(figsize=(10, top_n/2))
#     ax.barh(range(len(importance_df)), importance_df['importance'].values)
#     ax.set_yticks(range(len(importance_df)))
#     ax.set_yticklabels(importance_df['feature'].values)
#     ax.set_xlabel('Importance')
#     ax.set_title(f'{title} (Top {top_n})')
#     ax.invert_yaxis()
    
#     for i, v in enumerate(importance_df['importance'].values):
#         ax.text(v + 0.01, i, f'{v:.4f}', va='center')
    
#     plt.tight_layout()
#     plt.show()


# def plot_multiple_roc_curves(models_dict, X_test, y_test):
#     """
#     –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–¥–Ω–æ–º ROC –≥—Ä–∞—Ñ–∏–∫–µ (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ensemble).
    
#     Parameters:
#     -----------
#     models_dict : dict
#         {model_name: model}
#     X_test : pd.DataFrame
#         –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
#     y_test : pd.Series
#         –¢–µ—Å—Ç–æ–≤—ã–π —Ç–∞—Ä–≥–µ—Ç
#     """
#     plt.figure(figsize=(10, 8))
    
#     for model_name, model in models_dict.items():
#         y_pred_proba = model.predict_proba(X_test)[:, 1]
#         fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
#         roc_auc = auc(fpr, tpr)
        
#         plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.4f})')
    
#     plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
#     plt.xlim([0.0, 1.0])
#     plt.ylim([0.0, 1.05])
#     plt.xlabel('False Positive Rate')
#     plt.ylabel('True Positive Rate')
#     plt.title('ROC-AUC –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π')
#     plt.legend(loc="lower right")
#     plt.grid(True, alpha=0.3)
#     plt.tight_layout()
#     plt.show()


# def plot_confusion_matrix(y_true, y_pred, model_name="Model"):
#     """
#     –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ TP, FP, TN, FN).
    
#     Parameters:
#     -----------
#     y_true : array-like
#         –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
#     y_pred : array-like
#         –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
#     model_name : str
#         –ò–º—è –º–æ–¥–µ–ª–∏
#     """
#     cm = confusion_matrix(y_true, y_pred)
    
#     fig, ax = plt.subplots(figsize=(8, 6))
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
#                 xticklabels=['Non-Fraud', 'Fraud'],
#                 yticklabels=['Non-Fraud', 'Fraud'])
#     ax.set_xlabel('Predicted')
#     ax.set_ylabel('True')
#     ax.set_title(f'Confusion Matrix - {model_name}')
#     plt.tight_layout()
#     plt.show()


# def plot_cross_val_results(cv_results, metrics=['AUC', 'Precision', 'Recall', 'F1']):
#     """
#     –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏).
    
#     Parameters:
#     -----------
#     cv_results : dict
#         –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ cross_val_evaluate
#     metrics : list
#         –ö–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
#     """
#     fig, axes = plt.subplots(2, 2, figsize=(12, 8))
#     axes = axes.flatten()
    
#     for i, metric in enumerate(metrics):
#         if metric in cv_results:
#             scores = cv_results[metric]['scores']
#             mean = cv_results[metric]['mean']
#             std = cv_results[metric]['std']
            
#             axes[i].bar(range(len(scores)), scores, color='steelblue', alpha=0.7)
#             axes[i].axhline(mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean:.4f}')
#             axes[i].fill_between(range(len(scores)), mean-std, mean+std, alpha=0.2, color='red')
#             axes[i].set_xlabel('Fold')
#             axes[i].set_ylabel(metric)
#             axes[i].set_title(f'{metric} –ø–æ —Ñ–æ–ª–¥–∞–º')
#             axes[i].legend()
#             axes[i].grid(True, alpha=0.3)
    
#     plt.tight_layout()
#     plt.show()


# def plot_learning_curve(train_scores, val_scores, title="Learning Curve"):
#     """
#     –ö—Ä–∏–≤–∞—è –æ–±—É—á–µ–Ω–∏—è (–¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ overfitting).
    
#     Parameters:
#     -----------
#     train_scores : list
#         –°–∫–æ—Ä—ã –Ω–∞ train –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö
#     val_scores : list
#         –°–∫–æ—Ä—ã –Ω–∞ validation –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏—è—Ö
#     title : str
#         –ó–∞–≥–æ–ª–æ–≤–æ–∫
#     """
#     iterations = range(1, len(train_scores) + 1)
    
#     plt.figure(figsize=(10, 6))
#     plt.plot(iterations, train_scores, 'b-', label='Train Score', linewidth=2)
#     plt.plot(iterations, val_scores, 'r-', label='Validation Score', linewidth=2)
#     plt.xlabel('Iteration')
#     plt.ylabel('AUC')
#     plt.title(title)
#     plt.legend()
#     plt.grid(True, alpha=0.3)
#     plt.tight_layout()
#     plt.show()
    
def plot_dataset_overview(data, figsize=(14, 10)):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–∑–æ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞: –ø—Ä–æ–ø—É—Å–∫–∏, —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö.
    
    Parameters:
    -----------
    data : pd.DataFrame
        –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    figsize : tuple, default=(14, 10)
        –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã
    
    Returns:
    --------
    matplotlib.figure.Figure : –û–±—ä–µ–∫—Ç —Ñ–∏–≥—É—Ä—ã —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    """
    
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # ========================================================================
    # –ì—Ä–∞—Ñ–∏–∫ 1: –¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏
    # ========================================================================
    
    missing_pct = (data.isnull().sum() / len(data) * 100).sort_values(ascending=False).head(20)
    
    if len(missing_pct) > 0 and missing_pct.max() > 0:
        colors = ['red' if x > 80 else 'orange' if x > 50 else 'yellow' 
                  for x in missing_pct.values]
        
        axes[0, 0].barh(range(len(missing_pct)), missing_pct.values, 
                        color=colors, alpha=0.7, edgecolor='black')
        axes[0, 0].set_yticks(range(len(missing_pct)))
        axes[0, 0].set_yticklabels(missing_pct.index, fontsize=8)
        axes[0, 0].set_xlabel('% –ø—Ä–æ–ø—É—Å–∫–æ–≤', fontsize=10, fontweight='bold')
        axes[0, 0].set_title('üî¥ –¢–æ–ø-20: –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏', 
                             fontsize=11, fontweight='bold')
        axes[0, 0].axvline(x=80, color='red', linestyle='--', linewidth=1, alpha=0.5)
        axes[0, 0].axvline(x=50, color='orange', linestyle='--', linewidth=1, alpha=0.5)
        axes[0, 0].invert_yaxis()
        axes[0, 0].grid(axis='x', alpha=0.3)
    else:
        axes[0, 0].text(0.5, 0.5, '–ù–µ—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤', ha='center', va='center',
                        fontsize=12, transform=axes[0, 0].transAxes)
        axes[0, 0].set_title('üî¥ –¢–æ–ø-20: –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø—Ä–æ–ø—É—Å–∫–∞–º–∏', 
                             fontsize=11, fontweight='bold')
    
    # ========================================================================
    # –ì—Ä–∞—Ñ–∏–∫ 2: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    # ========================================================================
    
    missing_bins = pd.cut(data.isnull().sum(), 
                          bins=[-1, 0, 1000, 10000, 100000, float('inf')],
                          labels=['0', '1-1K', '1K-10K', '10K-100K', '>100K'])
    missing_dist = missing_bins.value_counts().sort_index()
    
    axes[0, 1].bar(range(len(missing_dist)), missing_dist.values, 
                   color='coral', alpha=0.7, edgecolor='black')
    axes[0, 1].set_xticks(range(len(missing_dist)))
    axes[0, 1].set_xticklabels(missing_dist.index, fontsize=9)
    axes[0, 1].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=10, fontweight='bold')
    axes[0, 1].set_title('üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤', fontsize=11, fontweight='bold')
    axes[0, 1].grid(axis='y', alpha=0.3)
    
    for i, v in enumerate(missing_dist.values):
        axes[0, 1].text(i, v, str(v), ha='center', va='bottom', 
                        fontsize=9, fontweight='bold')
    
    # ========================================================================
    # –ì—Ä–∞—Ñ–∏–∫ 3: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    # ========================================================================
    
    unique_bins = pd.cut(data.nunique(), 
                         bins=[-1, 2, 10, 100, 1000, float('inf')],
                         labels=['‚â§2', '3-10', '11-100', '101-1K', '>1K'])
    unique_dist = unique_bins.value_counts().sort_index()
    
    colors_unique = ['red', 'orange', 'yellow', 'lightgreen', 'green']
    axes[1, 0].bar(range(len(unique_dist)), unique_dist.values, 
                   color=colors_unique[:len(unique_dist)], alpha=0.7, edgecolor='black')
    axes[1, 0].set_xticks(range(len(unique_dist)))
    axes[1, 0].set_xticklabels(unique_dist.index, fontsize=9)
    axes[1, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=10, fontweight='bold')
    axes[1, 0].set_title('üü¢ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö', fontsize=11, fontweight='bold')
    axes[1, 0].grid(axis='y', alpha=0.3)
    
    for i, v in enumerate(unique_dist.values):
        axes[1, 0].text(i, v, str(v), ha='center', va='bottom', 
                        fontsize=9, fontweight='bold')
    
    # ========================================================================
    # –ì—Ä–∞—Ñ–∏–∫ 4: –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    # ========================================================================
    
    type_counts = data.dtypes.value_counts()
    axes[1, 1].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%',
                   colors=plt.cm.Set3(range(len(type_counts))), startangle=90)
    axes[1, 1].set_title('üìà –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö', fontsize=11, fontweight='bold')
    
    plt.suptitle('üìä –ö–†–ê–¢–ö–ò–ô –û–ë–ó–û–† –î–ê–¢–ê–°–ï–¢–ê', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    return fig

# def analyze_feature_importance(pipe, X_train, save_csv=True, figsize=(16, 12)):
#     """
#     –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–¥–µ–ª–∏ –∏–∑ Pipeline.
    
#     Parameters:
#     -----------
#     pipe : sklearn.pipeline.Pipeline –∏–ª–∏ imblearn.pipeline.Pipeline
#         –û–±—É—á–µ–Ω–Ω—ã–π Pipeline —Å –º–æ–¥–µ–ª—å—é
#     X_train : pd.DataFrame
#         –î–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π)
#     save_csv : bool, default=True
#         –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV
#     figsize : tuple, default=(16, 12)
#         –†–∞–∑–º–µ—Ä —Ñ–∏–≥—É—Ä—ã —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    
#     Returns:
#     --------
#     pd.DataFrame : DataFrame —Å feature importance
#     """
    
#     print("\n" + "="*100)
#     print("–ê–ù–ê–õ–ò–ó FEATURE IMPORTANCE")
#     print("="*100)
    
#     # ========================================================================
#     # 1. –ü–æ–ª—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –≤–∞–∂–Ω–æ—Å—Ç–∏
#     # ========================================================================
    
#     model = pipe.named_steps['model']
#     feature_importance = model.feature_importances_
    
#     # ========================================================================
#     # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
#     # ========================================================================
    
#     print("\nüîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
#     # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ X_train
#     try:
#         feature_names = X_train.columns.tolist()
#         print(f"‚úì –ù–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ X_train: {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
#     except:
#         feature_names = [f'feature_{i}' for i in range(len(feature_importance))]
#         print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–¥–µ–∫—Å—ã: {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
#     # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
#     if len(feature_names) != len(feature_importance):
#         print(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
#         print(f"   feature_names: {len(feature_names)}")
#         print(f"   feature_importance: {len(feature_importance)}")
        
#         if len(feature_names) > len(feature_importance):
#             feature_names = feature_names[:len(feature_importance)]
#         else:
#             for i in range(len(feature_names), len(feature_importance)):
#                 feature_names.append(f'feature_{i}')
    
#     print(f"‚úì –ò—Ç–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(feature_names)}")
    
#     # –°–æ–∑–¥–∞—ë–º DataFrame
#     importance_df = pd.DataFrame({
#         'feature': feature_names,
#         'importance': feature_importance
#     }).sort_values('importance', ascending=False)
    
#     # ========================================================================
#     # 3. –¢–û–ü-30 –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í
#     # ========================================================================
    
#     print(f"\nüìä –¢–û–ü-30 –°–ê–ú–´–• –í–ê–ñ–ù–´–• –ü–†–ò–ó–ù–ê–ö–û–í:")
#     print(f"\n{'Rank':<6} {'Feature':<50} {'Importance':<15} {'Cumulative %'}")
#     print(f"{'='*90}")
    
#     cumulative_importance = 0
#     total_importance = importance_df['importance'].sum()
    
#     for idx, (rank, row) in enumerate(importance_df.head(30).iterrows(), 1):
#         cumulative_importance += row['importance']
#         cumulative_pct = cumulative_importance / total_importance * 100
        
#         feature_display = row['feature'][:48] + '..' if len(row['feature']) > 50 else row['feature']
#         print(f"{idx:<6} {feature_display:<50} {row['importance']:<15.6f} {cumulative_pct:>6.2f}%")
    
#     print(f"\nüí° –¢–æ–ø-30 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –æ–±—ä—è—Å–Ω—è—é—Ç {cumulative_pct:.2f}% –≤–∞–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏")
    
#     # ========================================================================
#     # 4. –°–¢–ê–¢–ò–°–¢–ò–ö–ê
#     # ========================================================================
    
#     print(f"\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
#     print(f"  –í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:       {len(importance_df)}")
#     print(f"  –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å imp > 0:   {(importance_df['importance'] > 0).sum()}")
#     print(f"  –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å imp = 0:   {(importance_df['importance'] == 0).sum()}")
#     print(f"  Max importance:        {importance_df['importance'].max():.6f} ({importance_df.iloc[0]['feature']})")
#     print(f"  Mean importance:       {importance_df['importance'].mean():.6f}")
#     print(f"  Median importance:     {importance_df['importance'].median():.6f}")
    
#     # ========================================================================
#     # 5. –ì–†–ê–§–ò–ö–ò
#     # ========================================================================
    
#     fig, axes = plt.subplots(2, 2, figsize=figsize)
    
#     # –ì—Ä–∞—Ñ–∏–∫ 1: –¢–û–ü-20
#     top_20 = importance_df.head(20).copy()
#     top_20['feature_short'] = top_20['feature'].apply(lambda x: x[:35] + '..' if len(x) > 37 else x)
    
#     axes[0, 0].barh(range(len(top_20)), top_20['importance'], color='steelblue', alpha=0.8)
#     axes[0, 0].set_yticks(range(len(top_20)))
#     axes[0, 0].set_yticklabels(top_20['feature_short'], fontsize=9)
#     axes[0, 0].invert_yaxis()
#     axes[0, 0].set_xlabel('Importance', fontsize=11, fontweight='bold')
#     axes[0, 0].set_title('–¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏', fontsize=13, fontweight='bold')
#     axes[0, 0].grid(axis='x', alpha=0.3)
    
#     # –ì—Ä–∞—Ñ–∏–∫ 2: Cumulative Importance
#     importance_df_sorted = importance_df.sort_values('importance', ascending=False).reset_index(drop=True)
#     importance_df_sorted['cumulative'] = importance_df_sorted['importance'].cumsum() / importance_df_sorted['importance'].sum() * 100
    
#     axes[0, 1].plot(range(1, len(importance_df_sorted) + 1), importance_df_sorted['cumulative'], 
#                     color='coral', linewidth=2)
#     axes[0, 1].axhline(y=80, color='red', linestyle='--', linewidth=1, label='80%')
#     axes[0, 1].axhline(y=90, color='orange', linestyle='--', linewidth=1, label='90%')
#     axes[0, 1].axhline(y=95, color='green', linestyle='--', linewidth=1, label='95%')
#     axes[0, 1].set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=11, fontweight='bold')
#     axes[0, 1].set_ylabel('Cumulative Importance (%)', fontsize=11, fontweight='bold')
#     axes[0, 1].set_title('–ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å', fontsize=13, fontweight='bold')
#     axes[0, 1].legend(loc='lower right')
#     axes[0, 1].grid(alpha=0.3)
    
#     n_80 = (importance_df_sorted['cumulative'] <= 80).sum() + 1
#     n_90 = (importance_df_sorted['cumulative'] <= 90).sum() + 1
#     n_95 = (importance_df_sorted['cumulative'] <= 95).sum() + 1
    
#     axes[0, 1].text(0.5, 0.3, f'{n_80} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 80%\n{n_90} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 90%\n{n_95} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí 95%',
#                     transform=axes[0, 1].transAxes, fontsize=11, 
#                     bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
    
#     # –ì—Ä–∞—Ñ–∏–∫ 3: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
#     axes[1, 0].hist(importance_df['importance'], bins=50, color='steelblue', 
#                     edgecolor='black', alpha=0.7)
#     axes[1, 0].axvline(x=importance_df['importance'].mean(), color='red', 
#                        linestyle='--', linewidth=2, label=f"Mean = {importance_df['importance'].mean():.6f}")
#     axes[1, 0].axvline(x=importance_df['importance'].median(), color='green', 
#                        linestyle='--', linewidth=2, label=f"Median = {importance_df['importance'].median():.6f}")
#     axes[1, 0].set_xlabel('Importance', fontsize=11, fontweight='bold')
#     axes[1, 0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', fontsize=11, fontweight='bold')
#     axes[1, 0].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Feature Importance', fontsize=13, fontweight='bold')
#     axes[1, 0].legend()
#     axes[1, 0].grid(alpha=0.3)
    
#     # –ì—Ä–∞—Ñ–∏–∫ 4: –¢–æ–ø-15 —Å —Ü–≤–µ—Ç–æ–º
#     top_15 = importance_df.head(15).copy().sort_values('importance', ascending=True)
#     top_15['feature_short'] = top_15['feature'].apply(lambda x: x[:30] + '..' if len(x) > 32 else x)
#     colors = ['coral' if x > importance_df['importance'].median() else 'steelblue' for x in top_15['importance']]
    
#     axes[1, 1].barh(range(len(top_15)), top_15['importance'], color=colors, alpha=0.8)
#     axes[1, 1].set_yticks(range(len(top_15)))
#     axes[1, 1].set_yticklabels(top_15['feature_short'], fontsize=9)
#     axes[1, 1].set_xlabel('Importance', fontsize=11, fontweight='bold')
#     axes[1, 1].set_title('–¢–æ–ø-15 (—Ü–≤–µ—Ç: –≤—ã—à–µ/–Ω–∏–∂–µ –º–µ–¥–∏–∞–Ω—ã)', fontsize=13, fontweight='bold')
#     axes[1, 1].grid(axis='x', alpha=0.3)
    
#     legend_elements = [
#         Patch(facecolor='coral', alpha=0.8, label='–í—ã—à–µ –º–µ–¥–∏–∞–Ω—ã'),
#         Patch(facecolor='steelblue', alpha=0.8, label='–ù–∏–∂–µ –º–µ–¥–∏–∞–Ω—ã')
#     ]
#     axes[1, 1].legend(handles=legend_elements, loc='lower right')
    
#     plt.tight_layout()
#     plt.show()
    
#     # ========================================================================
#     # 6. –ù–ò–ó–ö–û–ò–ù–§–û–†–ú–ê–¢–ò–í–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
#     # ========================================================================
    
#     print(f"\nüóëÔ∏è –ù–ò–ó–ö–û–ò–ù–§–û–†–ú–ê–¢–ò–í–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò:")
    
#     zero_importance = importance_df[importance_df['importance'] == 0]
#     print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å importance = 0: {len(zero_importance)}")
    
#     low_importance_threshold = total_importance * 0.001
#     low_importance = importance_df[importance_df['importance'] < low_importance_threshold]
#     print(f"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å importance < 0.1%: {len(low_importance)}")
    
#     print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
#     print(f"   - –ú–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å {len(zero_importance)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω—É–ª–µ–≤–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é")
#     print(f"   - –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å —É–¥–∞–ª–µ–Ω–∏–µ {len(low_importance)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é")
#     print(f"   - {n_80} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–∞—é—Ç 80% –≤–∞–∂–Ω–æ—Å—Ç–∏ ‚Üí –º–æ–∂–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –º–æ–¥–µ–ª—å")
    
#     # ========================================================================
#     # 7. –°–û–•–†–ê–ù–ï–ù–ò–ï
#     # ========================================================================
    
#     if save_csv:
#         importance_df.to_csv('feature_importance.csv', index=False)
#         print(f"\n‚úÖ Feature importance —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ 'feature_importance.csv'")
    
#     print(f"\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù!")
    
#     return importance_df


